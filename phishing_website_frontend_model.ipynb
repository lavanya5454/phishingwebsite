{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3Uue7GX3bLKiUMvBrEYDe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lavanya5454/phishingwebsite/blob/main/phishing_website_frontend_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC9K-OY4ZqWU",
        "outputId": "be6d02d5-bfeb-469c-d2d4-a08335885534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model and components successfully loaded!\n",
            "Model version: 1.0\n",
            "Training accuracy: 98.48%\n",
            "Training date: 2025-11-06\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# ============================================\n",
        "# LOAD SAVED MALICIOUS URL DETECTOR MODEL\n",
        "# ============================================\n",
        "\n",
        "with open('malicious_url_detector.pkl', 'rb') as f:\n",
        "    model_package = pickle.load(f)\n",
        "\n",
        "# Extract components\n",
        "model = model_package['model']\n",
        "tfidf_vectorizer = model_package['tfidf_vectorizer']\n",
        "label_encoder = model_package['label_encoder']\n",
        "feature_cols = model_package['feature_cols']\n",
        "KNOWN_LEGITIMATE_DOMAINS = model_package['whitelist']\n",
        "\n",
        "print(\"‚úÖ Model and components successfully loaded!\")\n",
        "print(f\"Model version: {model_package['version']}\")\n",
        "print(f\"Training accuracy: {model_package['training_accuracy']*100:.2f}%\")\n",
        "print(f\"Training date: {model_package['training_date']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHAu4q4T2ckJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok lightgbm xgboost wordcloud scikit-learn pandas numpy seaborn matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-aHVDr4NlMHB",
        "outputId": "db4925df-b1c2-423a-b10d-95b383da3d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.4.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.12/dist-packages (1.9.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.11.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "COMPLETE MALICIOUS URL DETECTOR - STREAMLIT APP FOR GOOGLE COLAB\n",
        "Run with ngrok tunnel - WITH DASHBOARD\n",
        "\"\"\"\n",
        "\n",
        "# ============================================\n",
        "# STEP 1: INSTALL PACKAGES\n",
        "# ============================================\n",
        "\n",
        "!pip install -q streamlit pyngrok plotly lightgbm scikit-learn\n",
        "\n",
        "# ============================================\n",
        "# STEP 2: SETUP NGROK\n",
        "# ============================================\n",
        "\n",
        "# Get your free token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "NGROK_TOKEN = \"358iAUThEHTDr2fTWujUnTCrLOC_2aSVWBLTc2yJJ8A6N2WSt\"  # ‚ö†Ô∏è REPLACE THIS!\n",
        "\n",
        "!ngrok authtoken {NGROK_TOKEN}\n",
        "\n",
        "# ============================================\n",
        "# STEP 3: CREATE STREAMLIT APP (Using Python)\n",
        "# ============================================\n",
        "\n",
        "app_code = '''import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "\n",
        "# Page Config\n",
        "st.set_page_config(\n",
        "    page_title=\"üõ°Ô∏è URL Safety Checker\",\n",
        "    page_icon=\"üõ°Ô∏è\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .main-header {\n",
        "        font-size: 3.5rem;\n",
        "        font-weight: 800;\n",
        "        text-align: center;\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "        padding: 2rem 0 1rem 0;\n",
        "    }\n",
        "    .safe-box {\n",
        "        background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);\n",
        "        border-left: 6px solid #28a745;\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 10px;\n",
        "        margin: 1.5rem 0;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .danger-box {\n",
        "        background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%);\n",
        "        border-left: 6px solid #dc3545;\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 10px;\n",
        "        margin: 1.5rem 0;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .stButton>button {\n",
        "        width: 100%;\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        font-weight: bold;\n",
        "        padding: 0.75rem;\n",
        "        border-radius: 8px;\n",
        "    }\n",
        "    .metric-card {\n",
        "        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 12px;\n",
        "        box-shadow: 0 4px 12px rgba(0,0,0,0.1);\n",
        "        text-align: center;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "    .stat-number {\n",
        "        font-size: 2.5rem;\n",
        "        font-weight: bold;\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Initialize session state for scan history\n",
        "if \"scan_history\" not in st.session_state:\n",
        "    st.session_state.scan_history = []\n",
        "\n",
        "# Helper Functions\n",
        "@st.cache_data\n",
        "def load_model():\n",
        "    try:\n",
        "        with open(\"malicious_url_detector.pkl\", \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "        st.error(\"‚ö†Ô∏è Model file not found! Upload malicious_url_detector.pkl\")\n",
        "        return None\n",
        "\n",
        "def count_special_chars(url):\n",
        "    return len(re.findall(r\"[^a-zA-Z0-9]\", str(url)))\n",
        "\n",
        "def calculate_entropy(url):\n",
        "    url = str(url)\n",
        "    if len(url) == 0:\n",
        "        return 0\n",
        "    entropy = 0\n",
        "    for x in range(256):\n",
        "        p_x = float(url.count(chr(x))) / len(url)\n",
        "        if p_x > 0:\n",
        "            entropy += - p_x * np.log2(p_x)\n",
        "    return entropy\n",
        "\n",
        "def having_ip_address(url):\n",
        "    match = re.search(\n",
        "        r\"(([01]?\\\\\\\\d\\\\\\\\d?|2[0-4]\\\\\\\\d|25[0-5])\\\\\\\\.){3}([01]?\\\\\\\\d\\\\\\\\d?|2[0-4]\\\\\\\\d|25[0-5])\", url)\n",
        "    return 1 if match else 0\n",
        "\n",
        "def has_suspicious_tld(url):\n",
        "    return 1 if any(tld in str(url).lower() for tld in [\".tk\", \".ml\", \".ga\", \".cf\", \".gq\"]) else 0\n",
        "\n",
        "def has_shortening_service(url):\n",
        "    return 1 if any(s in str(url).lower() for s in [\"bit.ly\", \"goo.gl\", \"tinyurl\"]) else 0\n",
        "\n",
        "def preprocess_url(url):\n",
        "    url = str(url).lower()\n",
        "    url = re.sub(r\"https?://\", \"\", url)\n",
        "    url = re.sub(r\"^www\\\\\\\\.\", \"\", url)\n",
        "    return url\n",
        "\n",
        "def extract_domain(url):\n",
        "    url = preprocess_url(url)\n",
        "    domain = url.split(\"/\")[0]\n",
        "    parts = domain.split(\".\")\n",
        "    return \".\".join(parts[-2:]) if len(parts) >= 2 else domain\n",
        "\n",
        "KNOWN_LEGITIMATE_DOMAINS = {\n",
        "    \"google.com\", \"youtube.com\", \"facebook.com\", \"github.com\", \"amazon.com\",\n",
        "    \"paypal.com\", \"netflix.com\", \"microsoft.com\", \"apple.com\", \"twitter.com\",\n",
        "    \"linkedin.com\", \"instagram.com\", \"reddit.com\", \"wikipedia.org\", \"stackoverflow.com\"\n",
        "}\n",
        "\n",
        "PHISHING_KEYWORDS = [\"verify\", \"confirm\", \"update\", \"secure\", \"login\", \"suspended\"]\n",
        "\n",
        "def analyze_url_security(url):\n",
        "    domain = extract_domain(url)\n",
        "    if domain in KNOWN_LEGITIMATE_DOMAINS:\n",
        "        return {\"risk_level\": \"SAFE\", \"reason\": \"‚úÖ Whitelisted domain\", \"confidence\": 0.99}\n",
        "    if has_suspicious_tld(url) and sum(1 for k in PHISHING_KEYWORDS if k in url.lower()) >= 2:\n",
        "        return {\"risk_level\": \"HIGH_RISK\", \"reason\": \"‚ö†Ô∏è Suspicious TLD + keywords\", \"confidence\": 0.85}\n",
        "    if having_ip_address(url):\n",
        "        return {\"risk_level\": \"MEDIUM_RISK\", \"reason\": \"‚ö†Ô∏è IP address URL\", \"confidence\": 0.75}\n",
        "    return None\n",
        "\n",
        "def predict_url(url, model_data):\n",
        "    model = model_data[\"model\"]\n",
        "    tfidf_vectorizer = model_data[\"tfidf_vectorizer\"]\n",
        "    label_encoder = model_data[\"label_encoder\"]\n",
        "    feature_cols = model_data[\"feature_cols\"]\n",
        "\n",
        "    analysis = analyze_url_security(url)\n",
        "    if analysis:\n",
        "        num_classes = len(label_encoder.classes_)\n",
        "        probs = np.zeros(num_classes)\n",
        "        if analysis[\"risk_level\"] == \"SAFE\":\n",
        "            idx = list(label_encoder.classes_).index(\"benign\")\n",
        "            probs[idx] = 0.99\n",
        "            return \"benign\", probs, analysis[\"reason\"]\n",
        "        elif analysis[\"risk_level\"] == \"HIGH_RISK\":\n",
        "            idx = list(label_encoder.classes_).index(\"phishing\")\n",
        "            probs[idx] = 0.85\n",
        "            return \"phishing\", probs, analysis[\"reason\"]\n",
        "\n",
        "    url_str = str(url)\n",
        "    features = {\n",
        "        \"url_length\": len(url_str),\n",
        "        \"num_dots\": url_str.count(\".\"),\n",
        "        \"num_hyphens\": url_str.count(\"-\"),\n",
        "        \"num_underscores\": url_str.count(\"_\"),\n",
        "        \"num_slashes\": url_str.count(\"/\"),\n",
        "        \"num_questions\": url_str.count(\"?\"),\n",
        "        \"num_equals\": url_str.count(\"=\"),\n",
        "        \"num_at\": url_str.count(\"@\"),\n",
        "        \"num_ampersands\": url_str.count(\"&\"),\n",
        "        \"num_digits\": sum(c.isdigit() for c in url_str),\n",
        "        \"digit_ratio\": sum(c.isdigit() for c in url_str) / max(len(url_str), 1),\n",
        "        \"num_special_chars\": count_special_chars(url),\n",
        "        \"entropy\": calculate_entropy(url),\n",
        "        \"use_of_ip\": having_ip_address(url),\n",
        "        \"is_https\": 1 if \"https\" in url_str.lower() else 0,\n",
        "        \"suspicious_tld\": has_suspicious_tld(url),\n",
        "        \"has_shortening\": has_shortening_service(url)\n",
        "    }\n",
        "\n",
        "    manual_values = [features[col] for col in feature_cols]\n",
        "    manual_sparse = csr_matrix([manual_values])\n",
        "    tfidf_sparse = tfidf_vectorizer.transform([preprocess_url(url)])\n",
        "    X_single = hstack([manual_sparse, tfidf_sparse])\n",
        "\n",
        "    pred_encoded = model.predict(X_single)[0]\n",
        "    pred_label = label_encoder.inverse_transform([pred_encoded])[0]\n",
        "    probs = model.predict_proba(X_single)[0]\n",
        "\n",
        "    return pred_label, probs, \"ü§ñ ML prediction\"\n",
        "\n",
        "def add_to_history(url, prediction, confidence, is_safe):\n",
        "    \"\"\"Add scan to history\"\"\"\n",
        "    st.session_state.scan_history.append({\n",
        "        \"timestamp\": datetime.now(),\n",
        "        \"url\": url,\n",
        "        \"prediction\": prediction,\n",
        "        \"confidence\": confidence,\n",
        "        \"is_safe\": is_safe\n",
        "    })\n",
        "    # Keep only last 100 scans\n",
        "    if len(st.session_state.scan_history) > 100:\n",
        "        st.session_state.scan_history.pop(0)\n",
        "\n",
        "# Main App\n",
        "def main():\n",
        "    st.markdown(\"<h1 class=\\\\\"main-header\\\\\">üõ°Ô∏è Phishing Website Detection</h1>\", unsafe_allow_html=True)\n",
        "    st.markdown(\"<p style=\\\\\"text-align:center;color:#666;font-size:1.2rem;\\\\\">AI-Powered Phishing Website Detection </p>\", unsafe_allow_html=True)\n",
        "\n",
        "    model_data = load_model()\n",
        "    if model_data is None:\n",
        "        st.stop()\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.markdown(\"### üîç Navigation\")\n",
        "        page = st.radio(\"\", [\"üìä Dashboard\", \"üè† URL Checker\", \"üìà Batch Analysis\", \"‚ÑπÔ∏è About\"])\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### üìà Model Info\")\n",
        "        st.metric(\"Accuracy\", f\"{model_data.get('training_accuracy', 0.96)*100:.1f}%\")\n",
        "        st.metric(\"Features\", \"5,017\")\n",
        "        st.metric(\"Scans Today\", len(st.session_state.scan_history))\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### üß™ Quick Tests\")\n",
        "        if st.button(\"‚úÖ Safe URL\", use_container_width=True):\n",
        "            st.session_state.test_url = \"https://www.google.com\"\n",
        "        if st.button(\"‚ö†Ô∏è Phishing\", use_container_width=True):\n",
        "            st.session_state.test_url = \"http://paypal-verify.tk\"\n",
        "        if st.button(\"üîí IP Address\", use_container_width=True):\n",
        "            st.session_state.test_url = \"http://192.168.1.1/admin\"\n",
        "\n",
        "    # ========================================\n",
        "    # PAGE: DASHBOARD\n",
        "    # ========================================\n",
        "    if page == \"üìä Dashboard\":\n",
        "        st.markdown(\"## üìä Security Dashboard\")\n",
        "        st.markdown(\"Real-time analytics and scan history\")\n",
        "\n",
        "        # Overview Stats\n",
        "        st.markdown(\"### üìà Overview Statistics\")\n",
        "\n",
        "        col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "        total_scans = len(st.session_state.scan_history)\n",
        "        safe_scans = sum(1 for s in st.session_state.scan_history if s[\"is_safe\"])\n",
        "        malicious_scans = total_scans - safe_scans\n",
        "        avg_confidence = np.mean([s[\"confidence\"] for s in st.session_state.scan_history]) * 100 if total_scans > 0 else 0\n",
        "\n",
        "        with col1:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"metric-card\">\n",
        "                <div class=\"stat-number\">{total_scans}</div>\n",
        "                <div style=\"color:#666;\">Total Scans</div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        with col2:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"metric-card\">\n",
        "                <div class=\"stat-number\" style=\"color:#28a745;\">{safe_scans}</div>\n",
        "                <div style=\"color:#666;\">Safe URLs</div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        with col3:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"metric-card\">\n",
        "                <div class=\"stat-number\" style=\"color:#dc3545;\">{malicious_scans}</div>\n",
        "                <div style=\"color:#666;\">Malicious URLs</div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        with col4:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"metric-card\">\n",
        "                <div class=\"stat-number\">{avg_confidence:.1f}%</div>\n",
        "                <div style=\"color:#666;\">Avg Confidence</div>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        if total_scans > 0:\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            # Charts Row 1\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                st.markdown(\"### ü•ß Classification Distribution\")\n",
        "\n",
        "                # Count predictions\n",
        "                pred_counts = {}\n",
        "                for scan in st.session_state.scan_history:\n",
        "                    pred = scan[\"prediction\"]\n",
        "                    pred_counts[pred] = pred_counts.get(pred, 0) + 1\n",
        "\n",
        "                fig = px.pie(\n",
        "                    values=list(pred_counts.values()),\n",
        "                    names=list(pred_counts.keys()),\n",
        "                    title=\"URL Classifications\",\n",
        "                    color_discrete_sequence=px.colors.qualitative.Set3\n",
        "                )\n",
        "                fig.update_layout(height=350)\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            with col2:\n",
        "                st.markdown(\"### üìä Safety Overview\")\n",
        "\n",
        "                safety_data = pd.DataFrame({\n",
        "                    \"Category\": [\"Safe\", \"Malicious\"],\n",
        "                    \"Count\": [safe_scans, malicious_scans],\n",
        "                    \"Percentage\": [\n",
        "                        (safe_scans/total_scans)*100 if total_scans > 0 else 0,\n",
        "                        (malicious_scans/total_scans)*100 if total_scans > 0 else 0\n",
        "                    ]\n",
        "                })\n",
        "\n",
        "                fig = go.Figure()\n",
        "                fig.add_trace(go.Bar(\n",
        "                    x=safety_data[\"Category\"],\n",
        "                    y=safety_data[\"Count\"],\n",
        "                    marker_color=[\"#28a745\", \"#dc3545\"],\n",
        "                    text=safety_data[\"Percentage\"].round(1),\n",
        "                    texttemplate=\"%{text}%\",\n",
        "                    textposition=\"outside\"\n",
        "                ))\n",
        "                fig.update_layout(\n",
        "                    title=\"Safe vs Malicious URLs\",\n",
        "                    height=350,\n",
        "                    showlegend=False\n",
        "                )\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            # Charts Row 2\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                st.markdown(\"### üìà Scans Over Time\")\n",
        "\n",
        "                # Group by hour\n",
        "                df_history = pd.DataFrame(st.session_state.scan_history)\n",
        "                df_history[\"hour\"] = df_history[\"timestamp\"].dt.strftime(\"%H:%M\")\n",
        "                scans_timeline = df_history.groupby(\"hour\").size().reset_index(name=\"count\")\n",
        "\n",
        "                fig = px.line(\n",
        "                    scans_timeline,\n",
        "                    x=\"hour\",\n",
        "                    y=\"count\",\n",
        "                    title=\"Scan Activity Timeline\",\n",
        "                    markers=True\n",
        "                )\n",
        "                fig.update_layout(height=300, xaxis_title=\"Time\", yaxis_title=\"Number of Scans\")\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            with col2:\n",
        "                st.markdown(\"### üéØ Confidence Distribution\")\n",
        "\n",
        "                confidences = [s[\"confidence\"] * 100 for s in st.session_state.scan_history]\n",
        "\n",
        "                fig = go.Figure()\n",
        "                fig.add_trace(go.Histogram(\n",
        "                    x=confidences,\n",
        "                    nbinsx=20,\n",
        "                    marker_color=\"#667eea\"\n",
        "                ))\n",
        "                fig.update_layout(\n",
        "                    title=\"Prediction Confidence Levels\",\n",
        "                    height=300,\n",
        "                    xaxis_title=\"Confidence (%)\",\n",
        "                    yaxis_title=\"Frequency\"\n",
        "                )\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            # Recent Scans Table\n",
        "            st.markdown(\"### üìã Recent Scan History\")\n",
        "\n",
        "            recent_scans = st.session_state.scan_history[-20:][::-1]  # Last 20, reversed\n",
        "\n",
        "            df_recent = pd.DataFrame([{\n",
        "                \"Time\": s[\"timestamp\"].strftime(\"%H:%M:%S\"),\n",
        "                \"URL\": s[\"url\"][:50] + \"...\" if len(s[\"url\"]) > 50 else s[\"url\"],\n",
        "                \"Prediction\": s[\"prediction\"].upper(),\n",
        "                \"Confidence\": f\"{s['confidence']*100:.1f}%\",\n",
        "                \"Status\": \"‚úÖ Safe\" if s[\"is_safe\"] else \"‚ö†Ô∏è Malicious\"\n",
        "            } for s in recent_scans])\n",
        "\n",
        "            st.dataframe(df_recent, use_container_width=True, hide_index=True)\n",
        "\n",
        "            # Clear history button\n",
        "            col1, col2, col3 = st.columns([1, 1, 1])\n",
        "            with col2:\n",
        "                if st.button(\"üóëÔ∏è Clear History\", type=\"secondary\", use_container_width=True):\n",
        "                    st.session_state.scan_history = []\n",
        "                    st.rerun()\n",
        "\n",
        "        else:\n",
        "            st.info(\"üìä No scans yet. Start analyzing URLs to see statistics here!\")\n",
        "            st.markdown(\"### üöÄ Get Started\")\n",
        "            st.markdown(\"Click on **URL Checker** or **Batch Analysis** to start scanning URLs.\")\n",
        "\n",
        "    # ========================================\n",
        "    # PAGE: URL CHECKER\n",
        "    # ========================================\n",
        "    elif page == \"üè† URL Checker\":\n",
        "        st.markdown(\"## üîé Single URL Analysis\")\n",
        "\n",
        "        url_input = st.text_input(\"Enter URL:\", st.session_state.get(\"test_url\", \"\"), placeholder=\"https://example.com\")\n",
        "\n",
        "        if st.button(\"üîç Analyze URL\", type=\"primary\"):\n",
        "            if url_input:\n",
        "                with st.spinner(\"Analyzing...\"):\n",
        "                    try:\n",
        "                        prediction, probabilities, reason = predict_url(url_input, model_data)\n",
        "                        is_safe = prediction == \"benign\"\n",
        "                        confidence = float(max(probabilities))\n",
        "\n",
        "                        # Add to history\n",
        "                        add_to_history(url_input, prediction, confidence, is_safe)\n",
        "\n",
        "                        if is_safe:\n",
        "                            st.markdown(f\"\"\"\n",
        "                            <div class=\"safe-box\">\n",
        "                                <h2>‚úÖ SAFE URL</h2>\n",
        "                                <p>This URL appears legitimate and safe.</p>\n",
        "                            </div>\n",
        "                            \"\"\", unsafe_allow_html=True)\n",
        "                        else:\n",
        "                            st.markdown(f\"\"\"\n",
        "                            <div class=\"danger-box\">\n",
        "                                <h2>‚ö†Ô∏è DANGEROUS - {prediction.upper()}</h2>\n",
        "                                <p>Do not visit this URL!</p>\n",
        "                            </div>\n",
        "                            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                        col1, col2, col3 = st.columns(3)\n",
        "                        col1.metric(\"Classification\", prediction.upper())\n",
        "                        col2.metric(\"Confidence\", f\"{confidence*100:.1f}%\")\n",
        "                        col3.metric(\"Domain\", extract_domain(url_input))\n",
        "\n",
        "                        st.info(reason)\n",
        "\n",
        "                        prob_df = pd.DataFrame({\n",
        "                            \"Class\": model_data[\"label_encoder\"].classes_,\n",
        "                            \"Probability\": probabilities * 100\n",
        "                        }).sort_values(\"Probability\", ascending=True)\n",
        "\n",
        "                        fig = go.Figure(go.Bar(\n",
        "                            x=prob_df[\"Probability\"],\n",
        "                            y=prob_df[\"Class\"],\n",
        "                            orientation=\"h\",\n",
        "                            marker_color=\"#667eea\"\n",
        "                        ))\n",
        "                        fig.update_layout(height=250, margin=dict(l=0,r=0,t=20,b=0), title=\"Probability Distribution\")\n",
        "                        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Error: {str(e)}\")\n",
        "            else:\n",
        "                st.warning(\"Please enter a URL\")\n",
        "\n",
        "    # ========================================\n",
        "    # PAGE: BATCH ANALYSIS\n",
        "    # ========================================\n",
        "    elif page == \"üìà Batch Analysis\":\n",
        "        st.markdown(\"## üìà Batch URL Analysis\")\n",
        "        uploaded = st.file_uploader(\"Upload CSV with 'url' column\", type=[\"csv\"])\n",
        "\n",
        "        if uploaded:\n",
        "            df = pd.read_csv(uploaded)\n",
        "            if \"url\" in df.columns:\n",
        "                st.success(f\"Loaded {len(df)} URLs\")\n",
        "\n",
        "                if st.button(\"Analyze All\", type=\"primary\"):\n",
        "                    progress = st.progress(0)\n",
        "                    results = []\n",
        "\n",
        "                    for idx, url in enumerate(df[\"url\"]):\n",
        "                        try:\n",
        "                            pred, probs, reason = predict_url(url, model_data)\n",
        "                            confidence = float(max(probs))\n",
        "                            is_safe = pred == \"benign\"\n",
        "\n",
        "                            # Add to history\n",
        "                            add_to_history(url, pred, confidence, is_safe)\n",
        "\n",
        "                            results.append({\n",
        "                                \"URL\": url,\n",
        "                                \"Prediction\": pred,\n",
        "                                \"Confidence\": f\"{confidence*100:.1f}%\",\n",
        "                                \"Safe\": is_safe\n",
        "                            })\n",
        "                        except:\n",
        "                            results.append({\"URL\": url, \"Prediction\": \"error\", \"Confidence\": \"N/A\", \"Safe\": False})\n",
        "                        progress.progress((idx + 1) / len(df))\n",
        "\n",
        "                    results_df = pd.DataFrame(results)\n",
        "\n",
        "                    col1, col2, col3 = st.columns(3)\n",
        "                    col1.metric(\"Safe URLs\", results_df[\"Safe\"].sum())\n",
        "                    col2.metric(\"Malicious\", len(results_df) - results_df[\"Safe\"].sum())\n",
        "                    col3.metric(\"Total Scanned\", len(results_df))\n",
        "\n",
        "                    st.dataframe(results_df, use_container_width=True)\n",
        "\n",
        "                    csv = results_df.to_csv(index=False)\n",
        "                    st.download_button(\"üì• Download Results\", csv, f\"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\")\n",
        "            else:\n",
        "                st.error(\"CSV must have 'url' column\")\n",
        "\n",
        "    # ========================================\n",
        "    # PAGE: ABOUT\n",
        "    # ========================================\n",
        "    else:\n",
        "        st.markdown(\"## ‚ÑπÔ∏è About\")\n",
        "        st.markdown(\"\"\"\n",
        "        ### üéØ URL Safety Checker\n",
        "\n",
        "        AI-powered malicious URL detection using:\n",
        "        - ‚úÖ Whitelist checking (15+ trusted domains)\n",
        "        - üîç Rule-based analysis (typosquatting, suspicious TLDs)\n",
        "        - ü§ñ Machine Learning (96%+ accuracy with LightGBM)\n",
        "\n",
        "        **Categories Detected:**\n",
        "        - üé£ **Phishing**: Fake sites stealing credentials\n",
        "        - ü¶† **Malware**: Sites distributing malicious software\n",
        "        - üö´ **Defacement**: Compromised/hacked websites\n",
        "        - ‚úÖ **Benign**: Safe, legitimate websites\n",
        "\n",
        "        ### üìä Model Performance\n",
        "        - **Accuracy**: 96.56%\n",
        "        - **Features**: 5,017 (17 manual + 5,000 TF-IDF)\n",
        "        - **Algorithm**: LightGBM with class balancing\n",
        "        - **Training Data**: 100,000 labeled URLs\n",
        "\n",
        "        ### üõ°Ô∏è Security Tips\n",
        "        - Always verify URLs before clicking\n",
        "        - Look for HTTPS and valid certificates\n",
        "        - Avoid suspicious TLDs (.tk, .ml, .ga, .cf, .gq)\n",
        "        - Never enter passwords on unfamiliar sites\n",
        "\n",
        "        **Stay safe online!**\n",
        "        \"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "# Write the app to file\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"‚úÖ Streamlit app created with Dashboard!\")\n",
        "\n",
        "# ============================================\n",
        "# STEP 4: RUN WITH NGROK\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üöÄ STARTING STREAMLIT APP\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Kill existing streamlit\n",
        "!pkill -f streamlit 2>/dev/null\n",
        "\n",
        "# Start streamlit\n",
        "proc = subprocess.Popen(\n",
        "    ['streamlit', 'run', 'app.py', '--server.port', '8501', '--server.headless', 'true'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "# Wait for it to start\n",
        "time.sleep(8)\n",
        "\n",
        "# Create ngrok tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéâ SUCCESS! APP IS RUNNING WITH DASHBOARD!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nüåê Public URL: {public_url}\")\n",
        "print(\"\\nüì± Click the link above!\")\n",
        "print(\"\\n‚ö†Ô∏è  Keep this notebook running!\")\n",
        "print(\"\\n\" + \"=\"*70 + \"\\n\")"
      ],
      "metadata": {
        "id": "aicspNmNnN7X",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8935b7d-1d81-491b-d312-4178f8d275af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "‚úÖ Streamlit app created with Dashboard!\n",
            "\n",
            "======================================================================\n",
            "üöÄ STARTING STREAMLIT APP\n",
            "======================================================================\n",
            "\n",
            "^C\n",
            "\n",
            "======================================================================\n",
            "üéâ SUCCESS! APP IS RUNNING WITH DASHBOARD!\n",
            "======================================================================\n",
            "\n",
            "üåê Public URL: NgrokTunnel: \"https://avulsed-unendorsed-alpha.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "\n",
            "üì± Click the link above!\n",
            "\n",
            "‚ö†Ô∏è  Keep this notebook running!\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n"
      ],
      "metadata": {
        "id": "UHgz6cBCqdQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0rBFruSwBOE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}